{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Problem 4 --- Simulating Synchronous SGD via Gradient Accumulation Under Limited GPU Budget (15 points)\n\n**Version: GPU (A100 / L4 on Google Colab)**\n\nIn large-scale distributed training, synchronous SGD with data parallelism increases the **global batch size** by aggregating gradients across many workers at every iteration. While access to GPU clusters may be limited, the machine learning behavior of synchronous SGD (large global batch updates) can be approximated on a single GPU using **gradient accumulation**.\n\nIn this problem, you will use a single GPU (A100 or L4) to simulate synchronous SGD across multiple workers by accumulating gradients over multiple mini-batches before performing a parameter update.\n\n---\n\n## Experimental Setup (Must Follow Exactly)\n\n| Parameter | Value |\n|---|---|\n| Dataset | CIFAR-10 |\n| Training subset | First 10,240 training images |\n| Test subset | First 2,048 test images |\n| Model | ResNet-18 (standard PyTorch) |\n| Optimizer | SGD with momentum = 0.9 |\n| Learning rate | 0.1 (constant; no warmup, no decay) |\n| Weight decay | 5e-4 |\n| Per-mini-batch size | 64 |\n| Data augmentation | Random crop + horizontal flip |\n| Mixed precision | Disabled |\n| Gradient clipping | Disabled |\n\nAll experiments must be run on a **single GPU**. Do not use data parallelism or distributed training.\n\n### Gradient Accumulation Factors\n\nIn real synchronous SGD with $N$ workers, the global batch size is $64 \\times N$. On a single GPU, you approximate this by accumulating gradients for $K$ steps:\n\n$$B_{\\text{effective}} = 64 \\times K$$\n\nWe use: $K \\in \\{1, 2, 4, 8\\}$\n\n### Fixed Epoch Budget\n\nEach configuration trains for **$E = 5$ epochs** over the 10,240-image training subset. Since one epoch consists of $\\lfloor 10240 / (64 \\times K) \\rfloor$ optimizer updates, the total number of updates $U$ varies by $K$:\n\n$$U = E \\times \\left\\lfloor \\frac{10240}{64 \\times K} \\right\\rfloor$$\n\n| $K$ | Eff. Batch | Updates/Epoch | Total $U$ (5 epochs) | Total Images |\n|---|---|---|---|---|\n| 1 | 64  | 160 | 800 | 51,200 |\n| 2 | 128 | 80  | 400 | 51,200 |\n| 4 | 256 | 40  | 200 | 51,200 |\n| 8 | 512 | 20  | 100 | 51,200 |\n\n> Every configuration sees the **same total number of training images** (51,200). Larger $K$ naturally results in fewer optimizer updates per epoch."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 0: Environment Setup & GPU Check\n",
    "\n",
    "First, let's verify we have GPU access and import all necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\nimport torchvision.models as models\nimport time\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import DataLoader, Subset\n\n# Check GPU availability\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")\nif device.type == 'cuda':\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\nelse:\n    raise RuntimeError(\"GPU not available! Go to Runtime > Change runtime type > select GPU (A100 or L4).\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: Set Random Seeds for Reproducibility\n",
    "\n",
    "We fix random seeds so that results are reproducible across runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    \"\"\"Set all random seeds for reproducibility.\"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "print(\"Random seeds set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Prepare CIFAR-10 Data (Fixed Subsets)\n",
    "\n",
    "We use the **first 10,240 training images** and **first 2,048 test images** as fixed subsets.\n",
    "\n",
    "Data augmentation: random crop (with padding=4) and random horizontal flip for training; only normalization for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR-10 normalization statistics\n",
    "CIFAR10_MEAN = (0.4914, 0.4822, 0.4465)\n",
    "CIFAR10_STD = (0.2023, 0.1994, 0.2010)\n",
    "\n",
    "# Training transforms: random crop + horizontal flip\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(CIFAR10_MEAN, CIFAR10_STD),\n",
    "])\n",
    "\n",
    "# Test transforms: only normalization\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(CIFAR10_MEAN, CIFAR10_STD),\n",
    "])\n",
    "\n",
    "# Download CIFAR-10\n",
    "full_train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=train_transform\n",
    ")\n",
    "full_test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=test_transform\n",
    ")\n",
    "\n",
    "# Fixed subsets\n",
    "train_subset = Subset(full_train_dataset, range(10240))\n",
    "test_subset = Subset(full_test_dataset, range(2048))\n",
    "\n",
    "print(f\"Training subset size: {len(train_subset)}\")\n",
    "print(f\"Test subset size: {len(test_subset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Helper Functions\n",
    "\n",
    "We define helper functions to create the model, data loaders, and run the training loop with gradient accumulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    \"\"\"Create a fresh ResNet-18 model for CIFAR-10.\"\"\"\n",
    "    model = models.resnet18(num_classes=10)\n",
    "    model = model.to(device)\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_optimizer(model):\n",
    "    \"\"\"Create SGD optimizer with the specified hyperparameters.\"\"\"\n",
    "    return optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "\n",
    "def create_train_loader():\n",
    "    \"\"\"Create training data loader with batch size 64.\n",
    "    \n",
    "    We set drop_last=False. The training subset (10,240) is divisible by 64,\n",
    "    so all batches will be full-sized.\n",
    "    \"\"\"\n",
    "    return DataLoader(train_subset, batch_size=64, shuffle=True,\n",
    "                      num_workers=2, pin_memory=True, drop_last=False)\n",
    "\n",
    "\n",
    "def create_test_loader():\n",
    "    \"\"\"Create test data loader.\"\"\"\n",
    "    return DataLoader(test_subset, batch_size=256, shuffle=False,\n",
    "                      num_workers=2, pin_memory=True)\n",
    "\n",
    "\n",
    "def evaluate(model, test_loader):\n",
    "    \"\"\"Evaluate model accuracy on the test subset.\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    return 100.0 * correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Gradient Accumulation\n",
    "\n",
    "In standard training, we do:\n",
    "1. Forward pass on a mini-batch\n",
    "2. Backward pass to compute gradients\n",
    "3. Optimizer step to update parameters\n",
    "4. Zero gradients\n",
    "\n",
    "With gradient accumulation ($K$ steps), we:\n",
    "1. **Repeat $K$ times**: forward + backward (gradients accumulate in `.grad`)\n",
    "2. **Divide accumulated gradients by $K$** (to get the average)\n",
    "3. Optimizer step\n",
    "4. Zero gradients\n",
    "\n",
    "This simulates a batch of size $64 \\times K$ using $K$ mini-batches of size 64."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Micro-Iteration Time (Forward+Backward) vs $K$ [4 points]\n",
    "\n",
    "**Task:** For each value of $K$, measure the average time (in ms) for a single *micro-iteration* (one forward and backward pass on a mini-batch of size 64).\n",
    "\n",
    "- Warm up for 20 micro-iterations (not timed)\n",
    "- Time the next 80 micro-iterations and report the mean\n",
    "- Plot micro-iteration time vs. $K$\n",
    "\n",
    "**Why do we warm up?** The first few iterations on GPU involve JIT compilation, memory allocation, and CUDA kernel caching. Warming up ensures stable timing measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "K_values = [1, 2, 4, 8]\nmicro_iter_times = {}  # K -> mean time in ms\n\nfor K in K_values:\n    print(f\"\\n--- Measuring micro-iteration time for K={K} ---\")\n    set_seed(42)\n    model = create_model()\n    optimizer = create_optimizer(model)\n    criterion = nn.CrossEntropyLoss()\n    train_loader = create_train_loader()\n\n    model.train()\n\n    data_iter_ref = [iter(train_loader)]\n\n    def get_batch():\n        \"\"\"Get the next mini-batch, cycling through the dataset.\"\"\"\n        try:\n            return next(data_iter_ref[0])\n        except StopIteration:\n            data_iter_ref[0] = iter(train_loader)\n            return next(data_iter_ref[0])\n\n    # TODO: Warmup for 20 micro-iterations (not timed)\n    # Remember to move data to device with .to(device)\n\n    # TODO: Time 80 micro-iterations\n    # - For each micro-iteration: forward pass, compute loss, backward pass\n    # - Use torch.cuda.synchronize() before start/end timing for accurate GPU measurement\n    # - Measure time (in ms) for each micro-iteration\n    # - Do optimizer step every K micro-iterations to avoid unbounded gradient accumulation\n    # - Store mean time in micro_iter_times[K]\n\n    # YOUR CODE HERE\n    raise NotImplementedError()\n\n    del model, optimizer\n    torch.cuda.empty_cache()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot: Micro-iteration time vs K\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(K_values, [micro_iter_times[k] for k in K_values], 'bo-', markersize=8, linewidth=2)\n",
    "plt.xlabel('Gradient Accumulation Factor K', fontsize=13)\n",
    "plt.ylabel('Micro-Iteration Time (ms)', fontsize=13)\n",
    "plt.title('Part 1: Micro-Iteration Time vs K', fontsize=14)\n",
    "plt.xticks(K_values)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Part 1: Your Answer\n\n**Explain why the micro-iteration time does or does not change with $K$ in a single-GPU setup.**\n\n*Your answer here:*"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Part 2: Update Time and Effective Throughput [4 points]\n\n**Task:** For each value of $K$, measure:\n- Average *optimizer update time* (seconds per optimizer step), averaged over the middle 60% of updates (skip first 20% and last 20%).\n\nThe total number of updates $U$ is computed per $K$ as $U = 5 \\times \\lfloor 10240 / (64 \\times K) \\rfloor$.\n\nThen compute the *effective throughput* (images/sec):\n$$\\text{Throughput} = \\frac{64 \\times K}{T_{\\text{update}}}$$\n\n- Plot throughput vs. effective batch size ($64 \\times K$)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "NUM_EPOCHS = 5\nTRAIN_SIZE = len(train_subset)  # 10240\n\nupdate_times = {}     # K -> mean update time in seconds\nthroughputs = {}       # K -> images/sec\n\nfor K in K_values:\n    U = NUM_EPOCHS * (TRAIN_SIZE // (64 * K))\n    skip = U // 5  # skip first/last 20%\n    print(f\"\\n--- Measuring update time for K={K} (U={U}, middle window: [{skip}:{U - skip}]) ---\")\n    set_seed(42)\n    model = create_model()\n    optimizer = create_optimizer(model)\n    criterion = nn.CrossEntropyLoss()\n    train_loader = create_train_loader()\n    data_iter_ref = [iter(train_loader)]\n\n    def get_batch():\n        try:\n            return next(data_iter_ref[0])\n        except StopIteration:\n            data_iter_ref[0] = iter(train_loader)\n            return next(data_iter_ref[0])\n\n    model.train()\n\n    # TODO: For each of U optimizer updates:\n    # - Use torch.cuda.synchronize() before start/end timing\n    # - Time the full update (K micro-iterations + optimizer step)\n    # - Each micro-iteration: get batch, move to device, forward, loss, (loss/K).backward()\n    # - After K micro-iterations: optimizer.step()\n    # - Record update time\n    # Then: average over middle 60% of updates (skip first/last 20%)\n    # Store mean_update_time in update_times[K]\n    # Compute throughput = (64 * K) / mean_update_time and store in throughputs[K]\n\n    # YOUR CODE HERE\n    raise NotImplementedError()\n\n    del model, optimizer\n    torch.cuda.empty_cache()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot: Throughput vs Effective Batch Size\n",
    "effective_batch_sizes = [64 * K for K in K_values]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(effective_batch_sizes, [throughputs[k] for k in K_values], 'rs-', markersize=8, linewidth=2)\n",
    "plt.xlabel('Effective Batch Size (64 x K)', fontsize=13)\n",
    "plt.ylabel('Throughput (images/sec)', fontsize=13)\n",
    "plt.title('Part 2: Effective Throughput vs Effective Batch Size', fontsize=14)\n",
    "plt.xticks(effective_batch_sizes)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Part 2: Your Answer\n\n**Does throughput improve proportionally with $K$? Why or why not?**\n\n*Your answer here:*"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Part 3: Convergence Under a Fixed Epoch Budget [4 points]\n\n**Task:** For each value of $K$, train for $E=5$ epochs (so $U$ varies by $K$) and record:\n- Training loss at each epoch boundary\n- Test accuracy at the end of training\n\nPlot training loss vs. epoch for all $K$ on the same figure.\n\n> All configurations see the same total data (51,200 images). Smaller $K$ gets more optimizer updates."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "NUM_EPOCHS = 5\nTRAIN_SIZE = len(train_subset)  # 10240\n\n# Store results\nall_losses = {}        # K -> list of (epoch, loss)\nfinal_test_accs = {}   # K -> test accuracy\n\ntest_loader = create_test_loader()\n\nfor K in K_values:\n    updates_per_epoch = TRAIN_SIZE // (64 * K)\n    U = NUM_EPOCHS * updates_per_epoch\n    print(f\"\\n{'='*60}\")\n    print(f\"Training with K={K} (effective batch size = {64*K})\")\n    print(f\"  Updates/epoch = {updates_per_epoch}, Total U = {U}\")\n    print(f\"{'='*60}\")\n\n    set_seed(42)\n    model = create_model()\n    optimizer = create_optimizer(model)\n    criterion = nn.CrossEntropyLoss()\n    train_loader = create_train_loader()\n    data_iter_ref = [iter(train_loader)]\n\n    def get_batch():\n        try:\n            return next(data_iter_ref[0])\n        except StopIteration:\n            data_iter_ref[0] = iter(train_loader)\n            return next(data_iter_ref[0])\n\n    model.train()\n\n    # TODO: Train for NUM_EPOCHS epochs, each with updates_per_epoch optimizer updates.\n    # For each epoch:\n    #   - Track running loss across all updates in the epoch\n    #   - Each update: zero_grad, K micro-iterations with (loss/K).backward(), optimizer.step()\n    #   - Remember to move data to device with .to(device)\n    #   - At end of epoch: compute average loss, append (epoch, avg_loss) to losses_log\n    #   - Print epoch loss\n    # After training: evaluate on test_loader, store in final_test_accs[K]\n    # Store losses_log in all_losses[K]\n\n    # YOUR CODE HERE\n    raise NotImplementedError()\n\n    del model, optimizer\n    torch.cuda.empty_cache()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Plot: Training loss vs epoch for all K\nplt.figure(figsize=(10, 6))\ncolors = ['blue', 'green', 'orange', 'red']\n\nfor K, color in zip(K_values, colors):\n    epochs = [x[0] for x in all_losses[K]]\n    losses = [x[1] for x in all_losses[K]]\n    plt.plot(epochs, losses, f'-o', color=color, markersize=6, linewidth=2,\n             label=f'K={K} (batch={64*K}, U={NUM_EPOCHS * (TRAIN_SIZE // (64 * K))})')\n\nplt.xlabel('Epoch', fontsize=13)\nplt.ylabel('Training Loss', fontsize=13)\nplt.title('Part 3: Training Loss vs Epoch (Fixed Epoch Budget, E=5)', fontsize=14)\nplt.legend(fontsize=12)\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n\n# Print final test accuracies\nprint(\"\\nFinal Test Accuracies:\")\nfor K in K_values:\n    U = NUM_EPOCHS * (TRAIN_SIZE // (64 * K))\n    print(f\"  K={K} (batch={64*K}, U={U}): {final_test_accs[K]:.2f}%\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Part 3: Your Answer\n\n**Discuss how increasing effective batch size affects convergence when all configurations train for the same number of epochs (same total data).**\n\n*Your answer here:*"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Required Summary Table\n",
    "\n",
    "Run the cell below to generate the summary table with all measured values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"=\"*90)\nprint(\"SUMMARY TABLE\")\nprint(\"=\"*90)\nprint(f\"{'K':>3} | {'Eff. Batch':>10} | {'Total U':>8} | {'Micro-Iter (ms)':>15} | {'Update Time (s)':>15} | {'Test Acc (%)':>12}\")\nprint(\"-\"*90)\nfor K in K_values:\n    U = NUM_EPOCHS * (TRAIN_SIZE // (64 * K))\n    print(f\"{K:>3} | {64*K:>10} | {U:>8} | {micro_iter_times[K]:>15.2f} | {update_times[K]:>15.4f} | {final_test_accs[K]:>12.2f}\")\nprint(\"=\"*90)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Connection to Real Synchronous SGD [3 points]\n",
    "\n",
    "Answer the following questions in the cells below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Q4a: Which aspects of synchronous SGD are captured by gradient accumulation?\n\n*Your answer here:*"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Q4b: Which system-level effects are missing?\n\n*Your answer here:*"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Q4c: In real multi-GPU synchronous SGD, how would the missing effects change iteration time, scaling efficiency, and the optimal number of workers?\n\n*Your answer here:*"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Notes\n\n- The goal is to observe trends; minor differences across A100 vs. L4 are expected.\n- All configurations train for E=5 epochs (51,200 images). The number of optimizer updates varies by K.\n- Do not modify the dataset subsets, model, or hyperparameters.\n- Keep your code deterministic where possible (random seeds are set above)."
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  },
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "gpuType": "A100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}